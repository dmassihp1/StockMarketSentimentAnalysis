I chose to complete the second prompt, which involved building a model that predicts stock prices based on social media sentiment. I took two dataset from kaggle, one that included tweets that included the top 20 most watched stocks on Yahoo Finance, and another that included information on stock prices (closing/adjusted closing price, high/low/open price, and volume). This dataset only included the data for one year (2021-2022), but with more time I would have scraped twitter data and built a dataset that spanned more years.
After combining the datasets based on date and stock price, I performed some preprocessing on the tweets. Mainly removing stopwords, usernames and the hashtag symbol, and converting everything to lowercase. With more time, I would also have done more preprocessing to remove emojis, which could be problematic when using this text to predict sentiments.  I chose not to do any lemmatization/stemming, since BERT models (which I use in the next step to predict sentiments), have shown not to be affected by this type of preprocessing. Finally, I removed any duplicate tweets and rows withna’s.

To find sentiment scores for the cleaned tweets, I used two models: a naive bayes classifier from python’s textblob package and a pretrained BERT model from hugging face that was trained on financial data (Reuters and Financial PhraseBank).  I ran the tweets through both these models, which both outputed a score from -1 (negative sentiment) to 1 (positive sentiment), and then took the average of these scores to construct a final sentiment score. Because these models took a while to make predictions from, I reduced the dataset to only 2000 rows. With more time and resources (mainly a GPU), would have used the entire dataset (around 50k rows) so that I could have a more comprehensive datasets for training my stock prediction models.

I next decided to build a random forest regression model and an xgboost model that would take sentiment score, the stock name, the previous day’s adjusted closing price, open price, high, low, and volume to predict the next day’s adjusted closing price. To do this I sorted the dataset by date and created a new column called ‘Adj Close Next’ which took a specific’s stocks closing price for the previous day. I also one-hot-encoded the company name variable. To avoid look-ahead bias, I split the dataset chronologically into a training (70% of data), validation, and test set.  I used the optuna package to perform bayesian hyperparameter selection for both these models, and evaluated them on RMSE for each iteration.  I chose RMSE because it tends to be less unstable/affected by outliers than other metrics. I ran each of the two models for around 50 trials/iterations, since past this the RMSE did not seem to be improving. Once I had the optimal hyperparameters, I evaluated both models on the test set and calculated MAPE and RMSE. Both models were comparable in performance. With more time, I would have liked to also build a more complex model like an LSTM or neural network, and would also take into account more features such as the historical stock price, the alpha (excess return) and beta (volatility) of the stocks.